{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "3e7f3e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path='C:/Users/cioffil/Desktop/DS/Github/Telegram_chatbots'\n",
    "os.chdir(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "eb134b2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [177]\u001b[0m, in \u001b[0;36m<cell line: 38>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m X_word2vec \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpickle_w2v_vectors\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# prepare dataframe\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m data_movielens_final_new\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata_movielens_final_new.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m data_movielens_final_new[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID_Length\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mdata_movielens_final_new[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mlen\u001b[39m)\n\u001b[0;32m     40\u001b[0m data_movielens_final_new[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mwhere(data_movielens_final_new[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID_Length\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m7\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mwhere(data_movielens_final_new[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID_Length\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m6\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m,np\u001b[38;5;241m.\u001b[39mwhere(data_movielens_final_new[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID_Length\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m5\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m00\u001b[39m\u001b[38;5;124m'\u001b[39m,np\u001b[38;5;241m.\u001b[39mwhere(data_movielens_final_new[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID_Length\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m4\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m000\u001b[39m\u001b[38;5;124m'\u001b[39m,np\u001b[38;5;241m.\u001b[39mwhere(data_movielens_final_new[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID_Length\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m3\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0000\u001b[39m\u001b[38;5;124m'\u001b[39m,np\u001b[38;5;241m.\u001b[39mwhere(data_movielens_final_new[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID_Length\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m2\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m00000\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m000000\u001b[39m\u001b[38;5;124m'\u001b[39m))))))\n",
      "File \u001b[1;32m~\\Desktop\\DS\\Github\\Telegram_chatbots\\venv\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Desktop\\DS\\Github\\Telegram_chatbots\\venv\\lib\\site-packages\\pandas\\io\\excel\\_base.py:465\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    460\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    461\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    462\u001b[0m     )\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 465\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43msqueeze\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfalse_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthousands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipfooter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmangle_dupe_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmangle_dupe_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    492\u001b[0m     \u001b[38;5;66;03m# make sure to close opened file handles\u001b[39;00m\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_close:\n",
      "File \u001b[1;32m~\\Desktop\\DS\\Github\\Telegram_chatbots\\venv\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1458\u001b[0m, in \u001b[0;36mExcelFile.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, squeeze, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[0;32m   1424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\n\u001b[0;32m   1425\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1426\u001b[0m     sheet_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds,\n\u001b[0;32m   1446\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, DataFrame] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mint\u001b[39m, DataFrame]:\n\u001b[0;32m   1447\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1448\u001b[0m \u001b[38;5;124;03m    Parse specified sheet(s) into a DataFrame.\u001b[39;00m\n\u001b[0;32m   1449\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;124;03m        DataFrame from the passed in Excel file.\u001b[39;00m\n\u001b[0;32m   1457\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mparse(\n\u001b[0;32m   1459\u001b[0m         sheet_name\u001b[38;5;241m=\u001b[39msheet_name,\n\u001b[0;32m   1460\u001b[0m         header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   1461\u001b[0m         names\u001b[38;5;241m=\u001b[39mnames,\n\u001b[0;32m   1462\u001b[0m         index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[0;32m   1463\u001b[0m         usecols\u001b[38;5;241m=\u001b[39musecols,\n\u001b[0;32m   1464\u001b[0m         squeeze\u001b[38;5;241m=\u001b[39msqueeze,\n\u001b[0;32m   1465\u001b[0m         converters\u001b[38;5;241m=\u001b[39mconverters,\n\u001b[0;32m   1466\u001b[0m         true_values\u001b[38;5;241m=\u001b[39mtrue_values,\n\u001b[0;32m   1467\u001b[0m         false_values\u001b[38;5;241m=\u001b[39mfalse_values,\n\u001b[0;32m   1468\u001b[0m         skiprows\u001b[38;5;241m=\u001b[39mskiprows,\n\u001b[0;32m   1469\u001b[0m         nrows\u001b[38;5;241m=\u001b[39mnrows,\n\u001b[0;32m   1470\u001b[0m         na_values\u001b[38;5;241m=\u001b[39mna_values,\n\u001b[0;32m   1471\u001b[0m         parse_dates\u001b[38;5;241m=\u001b[39mparse_dates,\n\u001b[0;32m   1472\u001b[0m         date_parser\u001b[38;5;241m=\u001b[39mdate_parser,\n\u001b[0;32m   1473\u001b[0m         thousands\u001b[38;5;241m=\u001b[39mthousands,\n\u001b[0;32m   1474\u001b[0m         comment\u001b[38;5;241m=\u001b[39mcomment,\n\u001b[0;32m   1475\u001b[0m         skipfooter\u001b[38;5;241m=\u001b[39mskipfooter,\n\u001b[0;32m   1476\u001b[0m         convert_float\u001b[38;5;241m=\u001b[39mconvert_float,\n\u001b[0;32m   1477\u001b[0m         mangle_dupe_cols\u001b[38;5;241m=\u001b[39mmangle_dupe_cols,\n\u001b[0;32m   1478\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds,\n\u001b[0;32m   1479\u001b[0m     )\n",
      "File \u001b[1;32m~\\Desktop\\DS\\Github\\Telegram_chatbots\\venv\\lib\\site-packages\\pandas\\io\\excel\\_base.py:638\u001b[0m, in \u001b[0;36mBaseExcelReader.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, squeeze, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# assume an integer if not a string\u001b[39;00m\n\u001b[0;32m    636\u001b[0m     sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_sheet_by_index(asheetname)\n\u001b[1;32m--> 638\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_sheet_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msheet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_float\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(sheet, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;66;03m# pyxlsb opens two TemporaryFiles\u001b[39;00m\n\u001b[0;32m    641\u001b[0m     sheet\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\Desktop\\DS\\Github\\Telegram_chatbots\\venv\\lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:575\u001b[0m, in \u001b[0;36mOpenpyxlReader.get_sheet_data\u001b[1;34m(self, sheet, convert_float)\u001b[0m\n\u001b[0;32m    573\u001b[0m data: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[Scalar]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    574\u001b[0m last_row_with_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 575\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row_number, row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sheet\u001b[38;5;241m.\u001b[39mrows):\n\u001b[0;32m    576\u001b[0m     converted_row \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_cell(cell, convert_float) \u001b[38;5;28;01mfor\u001b[39;00m cell \u001b[38;5;129;01min\u001b[39;00m row]\n\u001b[0;32m    577\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m converted_row \u001b[38;5;129;01mand\u001b[39;00m converted_row[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    578\u001b[0m         \u001b[38;5;66;03m# trim trailing empty elements\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\DS\\Github\\Telegram_chatbots\\venv\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79\u001b[0m, in \u001b[0;36mReadOnlyWorksheet._cells_by_row\u001b[1;34m(self, min_col, min_row, max_col, max_row, values_only)\u001b[0m\n\u001b[0;32m     75\u001b[0m src \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_source()\n\u001b[0;32m     76\u001b[0m parser \u001b[38;5;241m=\u001b[39m WorkSheetParser(src, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shared_strings,\n\u001b[0;32m     77\u001b[0m                          data_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mdata_only, epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mepoch,\n\u001b[0;32m     78\u001b[0m                          date_formats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39m_date_formats)\n\u001b[1;32m---> 79\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mparse():\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m max_row \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m idx \u001b[38;5;241m>\u001b[39m max_row:\n\u001b[0;32m     81\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\DS\\Github\\Telegram_chatbots\\venv\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:144\u001b[0m, in \u001b[0;36mWorkSheetParser.parse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    125\u001b[0m properties \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    126\u001b[0m     PRINT_TAG: (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprint_options\u001b[39m\u001b[38;5;124m'\u001b[39m, PrintOptions),\n\u001b[0;32m    127\u001b[0m     MARGINS_TAG: (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpage_margins\u001b[39m\u001b[38;5;124m'\u001b[39m, PageMargins),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    139\u001b[0m \n\u001b[0;32m    140\u001b[0m }\n\u001b[0;32m    142\u001b[0m it \u001b[38;5;241m=\u001b[39m iterparse(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource) \u001b[38;5;66;03m# add a finaliser to close the source when this becomes possible\u001b[39;00m\n\u001b[1;32m--> 144\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, element \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[0;32m    145\u001b[0m     tag_name \u001b[38;5;241m=\u001b[39m element\u001b[38;5;241m.\u001b[39mtag\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tag_name \u001b[38;5;129;01min\u001b[39;00m dispatcher:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\xml\\etree\\ElementTree.py:1256\u001b[0m, in \u001b[0;36miterparse.<locals>.iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1254\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m pullparser\u001b[38;5;241m.\u001b[39mread_events()\n\u001b[0;32m   1255\u001b[0m \u001b[38;5;66;03m# load event buffer\u001b[39;00m\n\u001b[1;32m-> 1256\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[0;32m   1258\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\zipfile.py:922\u001b[0m, in \u001b[0;36mZipExtFile.read\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    921\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof:\n\u001b[1;32m--> 922\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    923\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[0;32m    924\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_readbuffer \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\zipfile.py:990\u001b[0m, in \u001b[0;36mZipExtFile._read1\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    988\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39munconsumed_tail\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[1;32m--> 990\u001b[0m         data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    991\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    992\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read2(n)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\zipfile.py:1022\u001b[0m, in \u001b[0;36mZipExtFile._read2\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1019\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(n, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMIN_READ_SIZE)\n\u001b[0;32m   1020\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_left)\n\u001b[1;32m-> 1022\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fileobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_left \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data)\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\zipfile.py:743\u001b[0m, in \u001b[0;36m_SharedFile.read\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pos)\n\u001b[0;32m    742\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file\u001b[38;5;241m.\u001b[39mread(n)\n\u001b[1;32m--> 743\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtell\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    744\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"attention  :  pip install python-telegram-bot --upgrade    NOT pip install telegram\"\"\"\n",
    "\n",
    "# import libraries\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import pickle\n",
    "import emoji\n",
    "import re\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import simplemma\n",
    "import string\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import difflib\n",
    "import logging\n",
    "from typing import Dict\n",
    "\n",
    "from telegram import ReplyKeyboardMarkup, Update, ReplyKeyboardRemove,InlineKeyboardButton, InlineKeyboardMarkup\n",
    "from telegram.ext import (\n",
    "    Updater,\n",
    "    CommandHandler,\n",
    "    MessageHandler,\n",
    "    Filters,\n",
    "    ConversationHandler,\n",
    "    CallbackContext,CallbackQueryHandler,\n",
    " \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# upload w2v model\n",
    "model_w2v = pd.read_pickle('pickle_w2v')\n",
    "X_word2vec = pd.read_pickle('pickle_w2v_vectors')\n",
    "\n",
    "# prepare dataframe\n",
    "data_movielens_final_new=pd.read_excel('data_movielens_final_new.xlsx')\n",
    "data_movielens_final_new['ID_Length']=data_movielens_final_new['ID'].astype(str).apply(len)\n",
    "data_movielens_final_new['zeros']=np.where(data_movielens_final_new['ID_Length']==7, '', np.where(data_movielens_final_new['ID_Length']==6,'0',np.where(data_movielens_final_new['ID_Length']==5,'00',np.where(data_movielens_final_new['ID_Length']==4,'000',np.where(data_movielens_final_new['ID_Length']==3,'0000',np.where(data_movielens_final_new['ID_Length']==2,'00000','000000'))))))\n",
    "data_movielens_final_new['Links'] = 'https://www.imdb.com/title/tt'+data_movielens_final_new['zeros']+data_movielens_final_new['ID'].astype(str)\n",
    "\n",
    "# functions for search and reccomandation\n",
    "def search_plot_similarity_adjusted(text,encoding_method,encoded_corpus,dataframe,topk,model=None,vectorizer=None,features=None):\n",
    "\tTOKEN_LEMMA = [clean_text_lemma(text)]\n",
    "\tspace_query=encoding_method(TOKEN_LEMMA,model)\n",
    "\tcosineSimilarities = cosine_similarity(space_query, encoded_corpus).flatten()\n",
    "\tdf=dataframe.iloc[np.argsort(cosineSimilarities)[-topk*20:].tolist() ]\n",
    "\tdf['similarity']=np.sort(cosineSimilarities)[-topk*20:].tolist() \n",
    "\tdf['final_score']=(df['similarity']*0.87)+(df['votes_score']*0.13)\n",
    "\tdf=df.sort_values(['final_score'], ascending=False)\n",
    "\tdf=df.groupby('Title').first().reset_index()\n",
    "\tdf=df.nlargest(topk,'final_score')\n",
    "    \n",
    "\tdf=df[['Title','Links']]\n",
    "\n",
    "\treturn df\n",
    "def word2vec_encoding_query(text,model_w2v,percentage_of_vocabulary_to_use=None, min_count=5):\n",
    "    size=300\n",
    "    corpus = []\n",
    "    tokenizer = WordPunctTokenizer()\n",
    "    for sent in text:\n",
    "        corpus.append(tokenizer.tokenize(sent.lower().translate(str.maketrans('', '', string.punctuation))))\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    wordvec_arrays = np.zeros((len(corpus), 300)) \n",
    "    for i in range(len(corpus)):\n",
    "        count = 0\n",
    "        for word in corpus[i]:\n",
    "            try:\n",
    "                vec += model_w2v.wv[word].reshape((1, size)) \n",
    "                count += 1.\n",
    "            except KeyError:  # handling the case where the token is not in vocabulary\n",
    "                continue\n",
    "        if count != 0:\n",
    "            vec /= count\n",
    "        wordvec_arrays[i,:] = vec\n",
    "    \n",
    "    return   wordvec_arrays \n",
    "stopwords_en = stopwords.words('english')\n",
    "langdata = simplemma.load_data('en')\n",
    "\n",
    "def clean_text_lemma(text):\n",
    "    if type(text) == float:\n",
    "        return \"\"\n",
    "    temp = text.lower() \n",
    "    temp = re.sub(\"'\", \" \", temp) # in inglese rimuove le parole abbreviate ma anche in italiano serve a staccare le parola con apostrofo\n",
    "    temp=emoji.demojize(temp, language='en')\n",
    "    words = temp.split()\n",
    "    temp = re.sub(\"@[A-Za-z0-9_]+\",\"\", temp)\n",
    "    temp = re.sub(\"#[A-Za-z0-9_]+\",\"\", temp)\n",
    "    temp = re.sub(r'http\\S+', '', temp)\n",
    "    temp = re.sub('[()!?]', ' ', temp)\n",
    "    temp = re.sub('\\[.*?\\]',' ', temp)\n",
    "    temp = re.sub(\"[^a-z0-9èéàùòì]\",\" \", temp)\n",
    "    temp = re.sub(\" \\d+\", \" \", temp)\n",
    "    temp = re.sub(\"^[0-9]\", \" \", temp)\n",
    "    #temp = temp.split()\n",
    "    temp = WordPunctTokenizer().tokenize(temp)\n",
    "    temp = [simplemma.lemmatize(w, langdata) for w in temp if not w in stopwords_en]\n",
    "    temp = \" \".join(word for word in temp)\n",
    "    \n",
    "    return temp\n",
    "\n",
    "\n",
    "\n",
    "def search_movie_similarity_adjusted(title,encoding_method,encoded_corpus,dataframe,topk,model=None,vectorizer=None,features=None):\n",
    "\tdf=dataframe\n",
    "\t # ratio method is more accurate , but slower\n",
    "\tdf['sim'] = [difflib.SequenceMatcher(a=title.lower(), b=i.lower()).quick_ratio() for i in df['Title']   ]   \n",
    "\tdf=df.sort_values(['sim'], ascending=False)\n",
    "\tdf1=df.head(1)\n",
    "\ttitle_found=df1['Title'].item()\n",
    "\tdf2=df[df['Title']==title_found]\n",
    "\tdf2=df2.dropna(subset=['text_clean'])\n",
    "\tdf2['doc_len'] = df2['text_clean'].apply(lambda words: len(words.split()))\n",
    "\tdf2=df2.sort_values(['doc_len'], ascending=False)\n",
    "\tdf2=df2.head(1)\n",
    "\tdf2=df2.drop(['sim'], axis=1)\n",
    "\tquery_new=df2['text_clean'].item()\n",
    "\tquery_new\n",
    "\n",
    "#\n",
    "\t# print(\"Most similar to:\" + title_found)\n",
    "\t# print(\"Top \" +str(topk)+ \" titles, by plot similarity\")\n",
    "\tdf_new=search_plot_similarity_adjusted(text=query_new,encoding_method=encoding_method,encoded_corpus=encoded_corpus,dataframe=dataframe,topk=topk,model=model,vectorizer=vectorizer,features=features)\n",
    "\tdf_new=df_new[df_new['Title']!=title_found] \n",
    "\tdf_new['plot_searched']=query_new\n",
    "\tdf_new['Title_to_search']=title_found\n",
    "\tcols = df_new.columns.tolist()\n",
    "\tcols = cols[-1:] + cols[:-1]\n",
    "\tdf_new = df_new[cols]\n",
    "\treturn df_new\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# here start the telegram chatbot\n",
    "\n",
    "\n",
    "# Enable logging\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO\n",
    ")\n",
    "TOKEN='5389959641:AAFzapxb0HqNfNtEKCBrpVJzTx5AexVX5Bk'\n",
    "\n",
    "# State definitions for top level conversation\n",
    "CHOOSING,QUERY_PLOT,QUERY_TITLE,WHATDONOW = map(chr, range(4))\n",
    "# Shortcut for ConversationHandler.END\n",
    "END = ConversationHandler.END\n",
    "\n",
    "# Callback data\n",
    "ONE, TWO,THREE,FOUR = range(4)\n",
    "\n",
    "\n",
    "\n",
    "def start(update: Update, context: CallbackContext) -> int:\n",
    "    \"\"\"Start the conversation and ask user for input.\"\"\"\n",
    "    \n",
    "\n",
    "    keyboard = [\n",
    "        [\n",
    "            InlineKeyboardButton(\"Search movie by plot events\", callback_data=str(ONE)),\n",
    "            InlineKeyboardButton(\"Suggest movies by similarity\", callback_data=str(TWO)),\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    reply_markup = InlineKeyboardMarkup(keyboard)\n",
    "    \n",
    "\n",
    "    update.message.reply_text(\n",
    "        \n",
    "        \"Hi  ! I'm\" \"* Moviezam!* \\U0001F916\" \" I know everything about\"\"*  Movies!* \\U0001F4FD\" \"\\n\" \n",
    "        \"Do you want to search for movies with\" \"* a particular plot event?*\" \" \\n\" \n",
    "        \"Can i \"\"*suggest you similar movies *\"\"to the ones you like?\\n\" \n",
    "        \"Beware: my catalog is updated \" \"*until 2019*\"  \"\\U0001F622\" \"\\n\" \n",
    "        \"*Choose one*\"\" of the options below, I will do a search for you \\U0001F603 !\" \"\\n\"\n",
    "         \"To abort, simply type /stop.\",\n",
    "        #   reply_markup=reply_markup,parse_mode= 'Markdown',\n",
    "        reply_markup=reply_markup ,parse_mode= 'Markdown',\n",
    "    )\n",
    "    \n",
    "\n",
    "    return CHOOSING\n",
    "\n",
    "def answer_recommend(update: Update, context: CallbackContext) -> int:\n",
    "    \"\"\"Ask the user for info about the selected predefined choice.\"\"\"\n",
    "    query = update.callback_query\n",
    "    query.answer()\n",
    "    query.edit_message_text(\n",
    "        text=\"'Please write the title of a movie that you like, i will suggest you 5 similar movies'\"\n",
    "    )\n",
    "\n",
    "    return QUERY_TITLE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def stop(update: Update, context: CallbackContext) -> int:\n",
    "    \"\"\"End Conversation by command.\"\"\"\n",
    "    update.message.reply_text('Okay, bye! \\U0001F603'  \"\\n\"\n",
    "                             \"If you want to start again click or type /start\")\n",
    "\n",
    "    return END\n",
    "\n",
    "def answer_plot(update: Update, context: CallbackContext) -> int:\n",
    "    \"\"\"Show new choice of buttons\"\"\"\n",
    "    query = update.callback_query\n",
    "    query.answer()\n",
    "    query.edit_message_text(\n",
    "        text=\"Please write some plot events or details and i will show you some related movies\"\n",
    "    )\n",
    "    return QUERY_PLOT\n",
    "\n",
    "def echo_plot(update: Update, context: CallbackContext) -> None:\n",
    "        \n",
    "    text_to_search=update.message.text\n",
    "    df=search_plot_similarity_adjusted(text=text_to_search,encoding_method=word2vec_encoding_query,model=model_w2v,encoded_corpus=X_word2vec,dataframe=data_movielens_final_new,topk=10)\n",
    "    df_lista=df['Links'].tolist()\n",
    "    df_lista_titles=df['Title'].tolist()\n",
    "    update.message.reply_text(f'Movie 1: {df_lista_titles[0]}')                         \n",
    "    update.message.reply_text(df_lista[0])\n",
    "    update.message.reply_text(f'Movie 2: {df_lista_titles[1]}') \n",
    "    update.message.reply_text(df_lista[1])\n",
    "    update.message.reply_text(f'Movie 3: {df_lista_titles[2]}') \n",
    "    update.message.reply_text(df_lista[2])\n",
    "    update.message.reply_text(f'Movie 4: {df_lista_titles[3]}') \n",
    "    update.message.reply_text(df_lista[3])\n",
    "    update.message.reply_text(f'Movie 5: {df_lista_titles[4]}') \n",
    "    update.message.reply_text(df_lista[4])\n",
    "    \n",
    "    \n",
    "    keyboard = [\n",
    "        [\n",
    "            InlineKeyboardButton(\"Start over again\", callback_data=str(THREE)),\n",
    "            InlineKeyboardButton(\"I'm done for now\", callback_data=str(FOUR)),\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    reply_markup = InlineKeyboardMarkup(keyboard)\n",
    "    \n",
    "\n",
    "    update.message.reply_text(\n",
    "        \n",
    "           \"What do you want to do, now? \",\n",
    "        #   reply_markup=reply_markup,parse_mode= 'Markdown',\n",
    "        reply_markup=reply_markup ,parse_mode= 'Markdown',\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return WHATDONOW\n",
    "\n",
    "\n",
    "def echo_title(update: Update, context: CallbackContext) -> None:\n",
    "    text_to_search=update.message.text\n",
    "    df=search_movie_similarity_adjusted(title=text_to_search,encoding_method=word2vec_encoding_query,model=model_w2v,encoded_corpus=X_word2vec,dataframe=data_movielens_final_new,topk=10)\n",
    "    df_lista=df['Links'].tolist()\n",
    "    df_lista_titles=df['Title'].tolist()\n",
    "    title_found=df['Title_to_search'].tolist()\n",
    "    title_found=title_found[0]\n",
    "    update.message.reply_text(f'Title found in database : {title_found}')  \n",
    "    update.message.reply_text(f'Below you can find 5 most similar movies to:  {title_found}')  \n",
    "    update.message.reply_text(f'Movie 1: {df_lista_titles[0]}')                         \n",
    "    update.message.reply_text(df_lista[0])\n",
    "    update.message.reply_text(f'Movie 2: {df_lista_titles[1]}') \n",
    "    update.message.reply_text(df_lista[1])\n",
    "    update.message.reply_text(f'Movie 3: {df_lista_titles[2]}') \n",
    "    update.message.reply_text(df_lista[2])\n",
    "    update.message.reply_text(f'Movie 4: {df_lista_titles[3]}') \n",
    "    update.message.reply_text(df_lista[3])\n",
    "    update.message.reply_text(f'Movie 5: {df_lista_titles[4]}') \n",
    "    update.message.reply_text(df_lista[4])\n",
    "    \n",
    "    \n",
    "    keyboard = [\n",
    "        [\n",
    "            InlineKeyboardButton(\"Start over again\", callback_data=str(THREE)),\n",
    "            InlineKeyboardButton(\"I'm done for now\", callback_data=str(FOUR)),\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    reply_markup = InlineKeyboardMarkup(keyboard)\n",
    "    \n",
    "\n",
    "    update.message.reply_text(\n",
    "        \n",
    "           \"What do you want to do, now? \",\n",
    "        #   reply_markup=reply_markup,parse_mode= 'Markdown',\n",
    "        reply_markup=reply_markup ,parse_mode= 'Markdown',\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return WHATDONOW\n",
    "\n",
    "def startover(update: Update, context: CallbackContext) -> None:\n",
    "    \"\"\"Start the conversation and ask user for input.\"\"\"\n",
    "    \n",
    "\n",
    "    keyboard = [\n",
    "        [\n",
    "            InlineKeyboardButton(\"Search movie by plot events\", callback_data=str(ONE)),\n",
    "            InlineKeyboardButton(\"Suggest movies by similarity\", callback_data=str(TWO)),\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    reply_markup = InlineKeyboardMarkup(keyboard)\n",
    "    \n",
    "    query = update.callback_query\n",
    "    query.answer()\n",
    "    query.edit_message_text(\n",
    "        \"*Choose one*\"\" of the options below, I will do a search for you  \\U0001F603 ! \\n\"\n",
    "         \"To abort, simply type /stop.\",\n",
    "        #   reply_markup=reply_markup,parse_mode= 'Markdown',\n",
    "        reply_markup=reply_markup ,parse_mode= 'Markdown',\n",
    "    )\n",
    "\n",
    "\n",
    "    return CHOOSING\n",
    "\n",
    "\n",
    "def stop2(update: Update, context: CallbackContext) -> int:\n",
    "    \n",
    "    \n",
    "    \"\"\"End Conversation by command.\"\"\"\n",
    "    \n",
    "    query = update.callback_query\n",
    "    query.answer()\n",
    "    query.edit_message_text(\n",
    "       (                 'Okay, bye! \\U0001F603' \"\\n\"\n",
    "                             \"If you want to start again click or type /start\"),\n",
    "        #   reply_markup=reply_markup,parse_mode= 'Markdown',\n",
    "        \n",
    "    )\n",
    "\n",
    "    return END\n",
    "\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"Run the bot.\"\"\"\n",
    "    # Create the Updater and pass it your bot's token.\n",
    "    updater = Updater(TOKEN)\n",
    "\n",
    "    # Get the dispatcher to register handlers\n",
    "    dispatcher = updater.dispatcher\n",
    "\n",
    "    # Add conversation handler with the states CHOOSING, TYPING_CHOICE and TYPING_REPLY\n",
    "    conv_handler = ConversationHandler(\n",
    "        entry_points=[CommandHandler('start', start)],\n",
    "        states={\n",
    "            CHOOSING: [\n",
    "                 CallbackQueryHandler(answer_plot, pattern='^' + str(ONE) + '$'),\n",
    "                 CallbackQueryHandler(answer_recommend, pattern='^' + str(TWO) + '$'),\n",
    "              #  MessageHandler(\n",
    "               #     Filters.regex('^(Search movie by plot events)$'), answer_plot   ),\n",
    "                #MessageHandler(Filters.regex('^Recommend movies by similarity$'), answer_recommend),\n",
    "            ],\n",
    "            \n",
    "            \n",
    "            QUERY_PLOT: [MessageHandler(Filters.text & ~Filters.command, echo_plot)],\n",
    "            QUERY_TITLE: [MessageHandler(Filters.text & ~Filters.command, echo_title)],\n",
    "                \n",
    "             WHATDONOW: [\n",
    "                 CallbackQueryHandler(startover, pattern='^' + str(THREE) + '$'),\n",
    "                 CallbackQueryHandler(stop2, pattern='^' + str(FOUR) + '$'),\n",
    "              #  MessageHandler(\n",
    "               #     Filters.regex('^(Search movie by plot events)$'), answer_plot   ),\n",
    "                #MessageHandler(Filters.regex('^Recommend movies by similarity$'), answer_recommend),\n",
    "            ],\n",
    "       \n",
    "        },\n",
    "        \n",
    "        fallbacks=[CommandHandler('stop', stop)],\n",
    "    )\n",
    "\n",
    "    dispatcher.add_handler(conv_handler)\n",
    "\n",
    "    # Start the Bot\n",
    "    updater.start_polling()\n",
    "\n",
    "    # Run the bot until you press Ctrl-C or the process receives SIGINT,\n",
    "    # SIGTERM or SIGABRT. This should be used most of the time, since\n",
    "    # start_polling() is non-blocking and will stop the bot gracefully.\n",
    "    updater.idle()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "telegram_chatbots",
   "language": "python",
   "name": "telegram_chatbots"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
