{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "eb134b2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/movielens/data_movielens_final_new.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [172]\u001b[0m, in \u001b[0;36m<cell line: 38>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m X_word2vec \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpickle_w2v_vectors\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# prepare dataframe\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m data_movielens_final_new\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/movielens/data_movielens_final_new.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m data_movielens_final_new[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID_Length\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mdata_movielens_final_new[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mlen\u001b[39m)\n\u001b[0;32m     40\u001b[0m data_movielens_final_new[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mwhere(data_movielens_final_new[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID_Length\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m7\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mwhere(data_movielens_final_new[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID_Length\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m6\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m,np\u001b[38;5;241m.\u001b[39mwhere(data_movielens_final_new[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID_Length\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m5\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m00\u001b[39m\u001b[38;5;124m'\u001b[39m,np\u001b[38;5;241m.\u001b[39mwhere(data_movielens_final_new[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID_Length\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m4\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m000\u001b[39m\u001b[38;5;124m'\u001b[39m,np\u001b[38;5;241m.\u001b[39mwhere(data_movielens_final_new[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID_Length\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m3\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0000\u001b[39m\u001b[38;5;124m'\u001b[39m,np\u001b[38;5;241m.\u001b[39mwhere(data_movielens_final_new[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID_Length\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m2\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m00000\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m000000\u001b[39m\u001b[38;5;124m'\u001b[39m))))))\n",
      "File \u001b[1;32m~\\Desktop\\DS\\Github\\Telegram_chatbots\\venv\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Desktop\\DS\\Github\\Telegram_chatbots\\venv\\lib\\site-packages\\pandas\\io\\excel\\_base.py:457\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    456\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 457\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    460\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    461\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    462\u001b[0m     )\n",
      "File \u001b[1;32m~\\Desktop\\DS\\Github\\Telegram_chatbots\\venv\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1376\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1374\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1376\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1380\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1381\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1382\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1383\u001b[0m         )\n",
      "File \u001b[1;32m~\\Desktop\\DS\\Github\\Telegram_chatbots\\venv\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1250\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1248\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1252\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1253\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1254\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\Desktop\\DS\\Github\\Telegram_chatbots\\venv\\lib\\site-packages\\pandas\\io\\common.py:798\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    790\u001b[0m             handle,\n\u001b[0;32m    791\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    794\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    795\u001b[0m         )\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    799\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    801\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/movielens/data_movielens_final_new.xlsx'"
     ]
    }
   ],
   "source": [
    "\"\"\"attention  :  pip install python-telegram-bot --upgrade    NOT pip install telegram\"\"\"\n",
    "\n",
    "# import libraries\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import pickle\n",
    "import emoji\n",
    "import re\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import simplemma\n",
    "import string\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import difflib\n",
    "import logging\n",
    "from typing import Dict\n",
    "\n",
    "from telegram import ReplyKeyboardMarkup, Update, ReplyKeyboardRemove,InlineKeyboardButton, InlineKeyboardMarkup\n",
    "from telegram.ext import (\n",
    "    Updater,\n",
    "    CommandHandler,\n",
    "    MessageHandler,\n",
    "    Filters,\n",
    "    ConversationHandler,\n",
    "    CallbackContext,CallbackQueryHandler,\n",
    " \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# upload w2v model\n",
    "model_w2v = pd.read_pickle('pickle_w2v')\n",
    "X_word2vec = pd.read_pickle('pickle_w2v_vectors')\n",
    "\n",
    "# prepare dataframe\n",
    "data_movielens_final_new=pd.read_excel('data/movielens/data_movielens_final_new.xlsx')\n",
    "data_movielens_final_new['ID_Length']=data_movielens_final_new['ID'].astype(str).apply(len)\n",
    "data_movielens_final_new['zeros']=np.where(data_movielens_final_new['ID_Length']==7, '', np.where(data_movielens_final_new['ID_Length']==6,'0',np.where(data_movielens_final_new['ID_Length']==5,'00',np.where(data_movielens_final_new['ID_Length']==4,'000',np.where(data_movielens_final_new['ID_Length']==3,'0000',np.where(data_movielens_final_new['ID_Length']==2,'00000','000000'))))))\n",
    "data_movielens_final_new['Links'] = 'https://www.imdb.com/title/tt'+data_movielens_final_new['zeros']+data_movielens_final_new['ID'].astype(str)\n",
    "\n",
    "# functions for search and reccomandation\n",
    "def search_plot_similarity_adjusted(text,encoding_method,encoded_corpus,dataframe,topk,model=None,vectorizer=None,features=None):\n",
    "\tTOKEN_LEMMA = [clean_text_lemma(text)]\n",
    "\tspace_query=encoding_method(TOKEN_LEMMA,model)\n",
    "\tcosineSimilarities = cosine_similarity(space_query, encoded_corpus).flatten()\n",
    "\tdf=dataframe.iloc[np.argsort(cosineSimilarities)[-topk*20:].tolist() ]\n",
    "\tdf['similarity']=np.sort(cosineSimilarities)[-topk*20:].tolist() \n",
    "\tdf['final_score']=(df['similarity']*0.87)+(df['votes_score']*0.13)\n",
    "\tdf=df.sort_values(['final_score'], ascending=False)\n",
    "\tdf=df.groupby('Title').first().reset_index()\n",
    "\tdf=df.nlargest(topk,'final_score')\n",
    "    \n",
    "\tdf=df[['Title','Links']]\n",
    "\n",
    "\treturn df\n",
    "def word2vec_encoding_query(text,model_w2v,percentage_of_vocabulary_to_use=None, min_count=5):\n",
    "    size=300\n",
    "    corpus = []\n",
    "    tokenizer = WordPunctTokenizer()\n",
    "    for sent in text:\n",
    "        corpus.append(tokenizer.tokenize(sent.lower().translate(str.maketrans('', '', string.punctuation))))\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    wordvec_arrays = np.zeros((len(corpus), 300)) \n",
    "    for i in range(len(corpus)):\n",
    "        count = 0\n",
    "        for word in corpus[i]:\n",
    "            try:\n",
    "                vec += model_w2v.wv[word].reshape((1, size)) \n",
    "                count += 1.\n",
    "            except KeyError:  # handling the case where the token is not in vocabulary\n",
    "                continue\n",
    "        if count != 0:\n",
    "            vec /= count\n",
    "        wordvec_arrays[i,:] = vec\n",
    "    \n",
    "    return   wordvec_arrays \n",
    "stopwords_en = stopwords.words('english')\n",
    "langdata = simplemma.load_data('en')\n",
    "\n",
    "def clean_text_lemma(text):\n",
    "    if type(text) == float:\n",
    "        return \"\"\n",
    "    temp = text.lower() \n",
    "    temp = re.sub(\"'\", \" \", temp) # in inglese rimuove le parole abbreviate ma anche in italiano serve a staccare le parola con apostrofo\n",
    "    temp=emoji.demojize(temp, language='en')\n",
    "    words = temp.split()\n",
    "    temp = re.sub(\"@[A-Za-z0-9_]+\",\"\", temp)\n",
    "    temp = re.sub(\"#[A-Za-z0-9_]+\",\"\", temp)\n",
    "    temp = re.sub(r'http\\S+', '', temp)\n",
    "    temp = re.sub('[()!?]', ' ', temp)\n",
    "    temp = re.sub('\\[.*?\\]',' ', temp)\n",
    "    temp = re.sub(\"[^a-z0-9èéàùòì]\",\" \", temp)\n",
    "    temp = re.sub(\" \\d+\", \" \", temp)\n",
    "    temp = re.sub(\"^[0-9]\", \" \", temp)\n",
    "    #temp = temp.split()\n",
    "    temp = WordPunctTokenizer().tokenize(temp)\n",
    "    temp = [simplemma.lemmatize(w, langdata) for w in temp if not w in stopwords_en]\n",
    "    temp = \" \".join(word for word in temp)\n",
    "    \n",
    "    return temp\n",
    "\n",
    "\n",
    "\n",
    "def search_movie_similarity_adjusted(title,encoding_method,encoded_corpus,dataframe,topk,model=None,vectorizer=None,features=None):\n",
    "\tdf=dataframe\n",
    "\t # ratio method is more accurate , but slower\n",
    "\tdf['sim'] = [difflib.SequenceMatcher(a=title.lower(), b=i.lower()).quick_ratio() for i in df['Title']   ]   \n",
    "\tdf=df.sort_values(['sim'], ascending=False)\n",
    "\tdf1=df.head(1)\n",
    "\ttitle_found=df1['Title'].item()\n",
    "\tdf2=df[df['Title']==title_found]\n",
    "\tdf2=df2.dropna(subset=['text_clean'])\n",
    "\tdf2['doc_len'] = df2['text_clean'].apply(lambda words: len(words.split()))\n",
    "\tdf2=df2.sort_values(['doc_len'], ascending=False)\n",
    "\tdf2=df2.head(1)\n",
    "\tdf2=df2.drop(['sim'], axis=1)\n",
    "\tquery_new=df2['text_clean'].item()\n",
    "\tquery_new\n",
    "\n",
    "#\n",
    "\t# print(\"Most similar to:\" + title_found)\n",
    "\t# print(\"Top \" +str(topk)+ \" titles, by plot similarity\")\n",
    "\tdf_new=search_plot_similarity_adjusted(text=query_new,encoding_method=encoding_method,encoded_corpus=encoded_corpus,dataframe=dataframe,topk=topk,model=model,vectorizer=vectorizer,features=features)\n",
    "\tdf_new=df_new[df_new['Title']!=title_found] \n",
    "\tdf_new['plot_searched']=query_new\n",
    "\tdf_new['Title_to_search']=title_found\n",
    "\tcols = df_new.columns.tolist()\n",
    "\tcols = cols[-1:] + cols[:-1]\n",
    "\tdf_new = df_new[cols]\n",
    "\treturn df_new\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# here start the telegram chatbot\n",
    "\n",
    "\n",
    "# Enable logging\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO\n",
    ")\n",
    "TOKEN='5389959641:AAFzapxb0HqNfNtEKCBrpVJzTx5AexVX5Bk'\n",
    "\n",
    "# State definitions for top level conversation\n",
    "CHOOSING,QUERY_PLOT,QUERY_TITLE,WHATDONOW = map(chr, range(4))\n",
    "# Shortcut for ConversationHandler.END\n",
    "END = ConversationHandler.END\n",
    "\n",
    "# Callback data\n",
    "ONE, TWO,THREE,FOUR = range(4)\n",
    "\n",
    "\n",
    "\n",
    "def start(update: Update, context: CallbackContext) -> int:\n",
    "    \"\"\"Start the conversation and ask user for input.\"\"\"\n",
    "    \n",
    "\n",
    "    keyboard = [\n",
    "        [\n",
    "            InlineKeyboardButton(\"Search movie by plot events\", callback_data=str(ONE)),\n",
    "            InlineKeyboardButton(\"Suggest movies by similarity\", callback_data=str(TWO)),\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    reply_markup = InlineKeyboardMarkup(keyboard)\n",
    "    \n",
    "\n",
    "    update.message.reply_text(\n",
    "        \n",
    "        \"Hi  ! I'm\" \"* Moviezam!* \\U0001F916\" \" I know everything about\"\"*  Movies!* \\U0001F4FD\" \"\\n\" \n",
    "        \"Do you want to search for movies with\" \"* a particular plot event?*\" \" \\n\" \n",
    "        \"Can i \"\"*suggest you similar movies *\"\"to the ones you like?\\n\" \n",
    "        \"Beware: my catalog is updated \" \"*until 2019*\" \"\\n\" \n",
    "        \"*Choose one*\"\" of the options below, I will do a search for you \\U0001F603 !\" \"\\n\"\n",
    "         \"To abort, simply type /stop.\",\n",
    "        #   reply_markup=reply_markup,parse_mode= 'Markdown',\n",
    "        reply_markup=reply_markup ,parse_mode= 'Markdown',\n",
    "    )\n",
    "    \n",
    "\n",
    "    return CHOOSING\n",
    "\n",
    "def answer_recommend(update: Update, context: CallbackContext) -> int:\n",
    "    \"\"\"Ask the user for info about the selected predefined choice.\"\"\"\n",
    "    query = update.callback_query\n",
    "    query.answer()\n",
    "    query.edit_message_text(\n",
    "        text=\"'Please write the title of a movie that you like, i will suggest you 5 similar movies'\"\n",
    "    )\n",
    "\n",
    "    return QUERY_TITLE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def stop(update: Update, context: CallbackContext) -> int:\n",
    "    \"\"\"End Conversation by command.\"\"\"\n",
    "    update.message.reply_text('Okay, bye! \\U0001F603'  \"\\n\"\n",
    "                             \"If you want to start again click or type /start\")\n",
    "\n",
    "    return END\n",
    "\n",
    "def answer_plot(update: Update, context: CallbackContext) -> int:\n",
    "    \"\"\"Show new choice of buttons\"\"\"\n",
    "    query = update.callback_query\n",
    "    query.answer()\n",
    "    query.edit_message_text(\n",
    "        text=\"Please write some plot events or details and i will show you some related movies\"\n",
    "    )\n",
    "    return QUERY_PLOT\n",
    "\n",
    "def echo_plot(update: Update, context: CallbackContext) -> None:\n",
    "        \n",
    "    text_to_search=update.message.text\n",
    "    df=search_plot_similarity_adjusted(text=text_to_search,encoding_method=word2vec_encoding_query,model=model_w2v,encoded_corpus=X_word2vec,dataframe=data_movielens_final_new,topk=10)\n",
    "    df_lista=df['Links'].tolist()\n",
    "    df_lista_titles=df['Title'].tolist()\n",
    "    update.message.reply_text(f'Movie 1: {df_lista_titles[0]}')                         \n",
    "    update.message.reply_text(df_lista[0])\n",
    "    update.message.reply_text(f'Movie 2: {df_lista_titles[1]}') \n",
    "    update.message.reply_text(df_lista[1])\n",
    "    update.message.reply_text(f'Movie 3: {df_lista_titles[2]}') \n",
    "    update.message.reply_text(df_lista[2])\n",
    "    update.message.reply_text(f'Movie 4: {df_lista_titles[3]}') \n",
    "    update.message.reply_text(df_lista[3])\n",
    "    update.message.reply_text(f'Movie 5: {df_lista_titles[4]}') \n",
    "    update.message.reply_text(df_lista[4])\n",
    "    \n",
    "    \n",
    "    keyboard = [\n",
    "        [\n",
    "            InlineKeyboardButton(\"Start over again\", callback_data=str(THREE)),\n",
    "            InlineKeyboardButton(\"I'm done for now\", callback_data=str(FOUR)),\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    reply_markup = InlineKeyboardMarkup(keyboard)\n",
    "    \n",
    "\n",
    "    update.message.reply_text(\n",
    "        \n",
    "           \"What do you want to do, now? \",\n",
    "        #   reply_markup=reply_markup,parse_mode= 'Markdown',\n",
    "        reply_markup=reply_markup ,parse_mode= 'Markdown',\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return WHATDONOW\n",
    "\n",
    "\n",
    "def echo_title(update: Update, context: CallbackContext) -> None:\n",
    "    text_to_search=update.message.text\n",
    "    df=search_movie_similarity_adjusted(title=title_search,encoding_method=word2vec_encoding_query,model=model_w2v,encoded_corpus=X_word2vec,dataframe=data_movielens_final_new,topk=10)\n",
    "    df_lista=df['Links'].tolist()\n",
    "    df_lista_titles=df['Title'].tolist()\n",
    "    title_found=df['Title_to_search'].tolist()\n",
    "    title_found=title_found[0]\n",
    "    update.message.reply_text(f'Title found in database : {title_found}')  \n",
    "    update.message.reply_text(f'Below you can find 5 most similar movies to:  {title_found}')  \n",
    "    update.message.reply_text(f'Movie 1: {df_lista_titles[0]}')                         \n",
    "    update.message.reply_text(df_lista[0])\n",
    "    update.message.reply_text(f'Movie 2: {df_lista_titles[1]}') \n",
    "    update.message.reply_text(df_lista[1])\n",
    "    update.message.reply_text(f'Movie 3: {df_lista_titles[2]}') \n",
    "    update.message.reply_text(df_lista[2])\n",
    "    update.message.reply_text(f'Movie 4: {df_lista_titles[3]}') \n",
    "    update.message.reply_text(df_lista[3])\n",
    "    update.message.reply_text(f'Movie 5: {df_lista_titles[4]}') \n",
    "    update.message.reply_text(df_lista[4])\n",
    "    \n",
    "    \n",
    "    keyboard = [\n",
    "        [\n",
    "            InlineKeyboardButton(\"Start over again\", callback_data=str(THREE)),\n",
    "            InlineKeyboardButton(\"I'm done for now\", callback_data=str(FOUR)),\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    reply_markup = InlineKeyboardMarkup(keyboard)\n",
    "    \n",
    "\n",
    "    update.message.reply_text(\n",
    "        \n",
    "           \"What do you want to do, now? \",\n",
    "        #   reply_markup=reply_markup,parse_mode= 'Markdown',\n",
    "        reply_markup=reply_markup ,parse_mode= 'Markdown',\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return WHATDONOW\n",
    "\n",
    "def startover(update: Update, context: CallbackContext) -> None:\n",
    "    \"\"\"Start the conversation and ask user for input.\"\"\"\n",
    "    \n",
    "\n",
    "    keyboard = [\n",
    "        [\n",
    "            InlineKeyboardButton(\"Search movie by plot events\", callback_data=str(ONE)),\n",
    "            InlineKeyboardButton(\"Suggest movies by similarity\", callback_data=str(TWO)),\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    reply_markup = InlineKeyboardMarkup(keyboard)\n",
    "    \n",
    "    query = update.callback_query\n",
    "    query.answer()\n",
    "    query.edit_message_text(\n",
    "        \"*Choose one*\"\" of the options below, I will do a search for you  \\U0001F603 ! \\n\"\n",
    "         \"To abort, simply type /stop.\",\n",
    "        #   reply_markup=reply_markup,parse_mode= 'Markdown',\n",
    "        reply_markup=reply_markup ,parse_mode= 'Markdown',\n",
    "    )\n",
    "\n",
    "\n",
    "    return CHOOSING\n",
    "\n",
    "\n",
    "def stop2(update: Update, context: CallbackContext) -> int:\n",
    "    \n",
    "    \n",
    "    \"\"\"End Conversation by command.\"\"\"\n",
    "    \n",
    "    query = update.callback_query\n",
    "    query.answer()\n",
    "    query.edit_message_text(\n",
    "       (                 'Okay, bye! \\U0001F603' \"\\n\"\n",
    "                             \"If you want to start again click or type /start\"),\n",
    "        #   reply_markup=reply_markup,parse_mode= 'Markdown',\n",
    "        \n",
    "    )\n",
    "\n",
    "    return END\n",
    "\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"Run the bot.\"\"\"\n",
    "    # Create the Updater and pass it your bot's token.\n",
    "    updater = Updater(TOKEN)\n",
    "\n",
    "    # Get the dispatcher to register handlers\n",
    "    dispatcher = updater.dispatcher\n",
    "\n",
    "    # Add conversation handler with the states CHOOSING, TYPING_CHOICE and TYPING_REPLY\n",
    "    conv_handler = ConversationHandler(\n",
    "        entry_points=[CommandHandler('start', start)],\n",
    "        states={\n",
    "            CHOOSING: [\n",
    "                 CallbackQueryHandler(answer_plot, pattern='^' + str(ONE) + '$'),\n",
    "                 CallbackQueryHandler(answer_recommend, pattern='^' + str(TWO) + '$'),\n",
    "              #  MessageHandler(\n",
    "               #     Filters.regex('^(Search movie by plot events)$'), answer_plot   ),\n",
    "                #MessageHandler(Filters.regex('^Recommend movies by similarity$'), answer_recommend),\n",
    "            ],\n",
    "            \n",
    "            \n",
    "            QUERY_PLOT: [MessageHandler(Filters.text & ~Filters.command, echo_plot)],\n",
    "            QUERY_TITLE: [MessageHandler(Filters.text & ~Filters.command, echo_title)],\n",
    "                \n",
    "             WHATDONOW: [\n",
    "                 CallbackQueryHandler(startover, pattern='^' + str(THREE) + '$'),\n",
    "                 CallbackQueryHandler(stop2, pattern='^' + str(FOUR) + '$'),\n",
    "              #  MessageHandler(\n",
    "               #     Filters.regex('^(Search movie by plot events)$'), answer_plot   ),\n",
    "                #MessageHandler(Filters.regex('^Recommend movies by similarity$'), answer_recommend),\n",
    "            ],\n",
    "       \n",
    "        },\n",
    "        \n",
    "        fallbacks=[CommandHandler('stop', stop)],\n",
    "    )\n",
    "\n",
    "    dispatcher.add_handler(conv_handler)\n",
    "\n",
    "    # Start the Bot\n",
    "    updater.start_polling()\n",
    "\n",
    "    # Run the bot until you press Ctrl-C or the process receives SIGINT,\n",
    "    # SIGTERM or SIGABRT. This should be used most of the time, since\n",
    "    # start_polling() is non-blocking and will stop the bot gracefully.\n",
    "    updater.idle()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6d553ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import pickle\n",
    "import emoji\n",
    "import re\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import simplemma\n",
    "import string\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05b69f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_movielens_final_new=pd.read_excel('C:/Users/cioffil/Desktop/DS/Github/Moviezam/Moviezam/data/movielens/data_movielens_final_new.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee0e656b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload w2v\n",
    "model_w2v = pd.read_pickle('C:/Users/cioffil/Desktop/DS/Github/Moviezam/Moviezam/pickle_data/pickle_w2v')\n",
    "X_word2vec = pd.read_pickle('C:/Users/cioffil/Desktop/DS/Github/Moviezam/Moviezam/pickle_data/pickle_w2v_vectors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e4c98bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_plot_similarity_adjusted(text,encoding_method,encoded_corpus,dataframe,topk,model=None,vectorizer=None,features=None):\n",
    "\tTOKEN_LEMMA = [clean_text_lemma(text)]\n",
    "\tspace_query=encoding_method(TOKEN_LEMMA,model)\n",
    "\tcosineSimilarities = cosine_similarity(space_query, encoded_corpus).flatten()\n",
    "\tdf=dataframe.iloc[np.argsort(cosineSimilarities)[-topk*20:].tolist() ]\n",
    "\tdf['similarity']=np.sort(cosineSimilarities)[-topk*20:].tolist() \n",
    "\tdf['final_score']=(df['similarity']*0.87)+(df['votes_score']*0.13)\n",
    "\tdf=df.sort_values(['final_score'], ascending=False)\n",
    "\tdf=df.groupby('Title').first().reset_index()\n",
    "\tdf=df.nlargest(topk,'final_score')\n",
    "    \n",
    "\tdf=df[['Title','Links']]\n",
    "\n",
    "\treturn df\n",
    "def word2vec_encoding_query(text,model_w2v,percentage_of_vocabulary_to_use=None, min_count=5):\n",
    "    size=300\n",
    "    corpus = []\n",
    "    tokenizer = WordPunctTokenizer()\n",
    "    for sent in text:\n",
    "        corpus.append(tokenizer.tokenize(sent.lower().translate(str.maketrans('', '', string.punctuation))))\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    wordvec_arrays = np.zeros((len(corpus), 300)) \n",
    "    for i in range(len(corpus)):\n",
    "        count = 0\n",
    "        for word in corpus[i]:\n",
    "            try:\n",
    "                vec += model_w2v.wv[word].reshape((1, size)) \n",
    "                count += 1.\n",
    "            except KeyError:  # handling the case where the token is not in vocabulary\n",
    "                continue\n",
    "        if count != 0:\n",
    "            vec /= count\n",
    "        wordvec_arrays[i,:] = vec\n",
    "    \n",
    "    return   wordvec_arrays \n",
    "stopwords_en = stopwords.words('english')\n",
    "langdata = simplemma.load_data('en')\n",
    "\n",
    "def clean_text_lemma(text):\n",
    "    if type(text) == float:\n",
    "        return \"\"\n",
    "    temp = text.lower() \n",
    "    temp = re.sub(\"'\", \" \", temp) # in inglese rimuove le parole abbreviate ma anche in italiano serve a staccare le parola con apostrofo\n",
    "    temp=emoji.demojize(temp, language='en')\n",
    "    words = temp.split()\n",
    "    temp = re.sub(\"@[A-Za-z0-9_]+\",\"\", temp)\n",
    "    temp = re.sub(\"#[A-Za-z0-9_]+\",\"\", temp)\n",
    "    temp = re.sub(r'http\\S+', '', temp)\n",
    "    temp = re.sub('[()!?]', ' ', temp)\n",
    "    temp = re.sub('\\[.*?\\]',' ', temp)\n",
    "    temp = re.sub(\"[^a-z0-9èéàùòì]\",\" \", temp)\n",
    "    temp = re.sub(\" \\d+\", \" \", temp)\n",
    "    temp = re.sub(\"^[0-9]\", \" \", temp)\n",
    "    #temp = temp.split()\n",
    "    temp = WordPunctTokenizer().tokenize(temp)\n",
    "    temp = [simplemma.lemmatize(w, langdata) for w in temp if not w in stopwords_en]\n",
    "    temp = \" \".join(word for word in temp)\n",
    "    \n",
    "    return temp\n",
    "\n",
    "\n",
    "\n",
    "def search_movie_similarity_adjusted(title,encoding_method,encoded_corpus,dataframe,topk,model=None,vectorizer=None,features=None):\n",
    "\tdf=dataframe\n",
    "\t # ratio method is more accurate , but slower\n",
    "\tdf['sim'] = [difflib.SequenceMatcher(a=title.lower(), b=i.lower()).quick_ratio() for i in df['Title']   ]   \n",
    "\tdf=df.sort_values(['sim'], ascending=False)\n",
    "\tdf1=df.head(1)\n",
    "\ttitle_found=df1['Title'].item()\n",
    "\tdf2=df[df['Title']==title_found]\n",
    "\tdf2=df2.dropna(subset=['text_clean'])\n",
    "\tdf2['doc_len'] = df2['text_clean'].apply(lambda words: len(words.split()))\n",
    "\tdf2=df2.sort_values(['doc_len'], ascending=False)\n",
    "\tdf2=df2.head(1)\n",
    "\tdf2=df2.drop(['sim'], axis=1)\n",
    "\tquery_new=df2['text_clean'].item()\n",
    "\tquery_new\n",
    "\n",
    "#\n",
    "\t# print(\"Most similar to:\" + title_found)\n",
    "\t# print(\"Top \" +str(topk)+ \" titles, by plot similarity\")\n",
    "\tdf_new=search_plot_similarity_adjusted(text=query_new,encoding_method=encoding_method,encoded_corpus=encoded_corpus,dataframe=dataframe,topk=topk,model=model,vectorizer=vectorizer,features=features)\n",
    "\tdf_new=df_new[df_new['Title']!=title_found] \n",
    "\tdf_new['plot_searched']=query_new\n",
    "\tdf_new['Title_to_search']=title_found\n",
    "\tcols = df_new.columns.tolist()\n",
    "\tcols = cols[-1:] + cols[:-1]\n",
    "\tdf_new = df_new[cols]\n",
    "\treturn df_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "67655921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>Title</th>\n",
       "      <th>original_title</th>\n",
       "      <th>votes_score</th>\n",
       "      <th>year</th>\n",
       "      <th>languages</th>\n",
       "      <th>overview</th>\n",
       "      <th>plot_outline</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>ID_Length</th>\n",
       "      <th>zeros</th>\n",
       "      <th>Links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134999</th>\n",
       "      <td>134999</td>\n",
       "      <td>1003009</td>\n",
       "      <td>En su recorrido por el interior de la Casona E...</td>\n",
       "      <td>en su recorrido por el interior de la casona e...</td>\n",
       "      <td>Legend Quest: The Legend of La Nahuala</td>\n",
       "      <td>La leyenda de la Nahuala</td>\n",
       "      <td>0.419209</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>['Spanish']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The movie takes place in the year 1807 in the ...</td>\n",
       "      <td>Sinópsis Corre el año de 1807 en la Ciudad de ...</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>https://www.imdb.com/title/tt1003009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135000</th>\n",
       "      <td>135000</td>\n",
       "      <td>1003009</td>\n",
       "      <td>Among these stories is \"The Legend of the Nahu...</td>\n",
       "      <td>among story legend nahuala accord old abandon ...</td>\n",
       "      <td>Legend Quest: The Legend of La Nahuala</td>\n",
       "      <td>La leyenda de la Nahuala</td>\n",
       "      <td>0.419209</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>['Spanish']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The movie takes place in the year 1807 in the ...</td>\n",
       "      <td>Sinópsis Corre el año de 1807 en la Ciudad de ...</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>https://www.imdb.com/title/tt1003009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135001</th>\n",
       "      <td>135001</td>\n",
       "      <td>1003009</td>\n",
       "      <td>In his journey inside the bewitched house, Leo...</td>\n",
       "      <td>journey inside bewitch house Leo face danger s...</td>\n",
       "      <td>Legend Quest: The Legend of La Nahuala</td>\n",
       "      <td>La leyenda de la Nahuala</td>\n",
       "      <td>0.419209</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>['Spanish']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The movie takes place in the year 1807 in the ...</td>\n",
       "      <td>Sinópsis Corre el año de 1807 en la Ciudad de ...</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>https://www.imdb.com/title/tt1003009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135002</th>\n",
       "      <td>135002</td>\n",
       "      <td>5606664</td>\n",
       "      <td>She finds what looks like filing cabinets and ...</td>\n",
       "      <td>find look like filing cabinet try dig abra ant...</td>\n",
       "      <td>Doctor Sleep</td>\n",
       "      <td>Doctor Sleep</td>\n",
       "      <td>0.820093</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>['English']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>On highways across America, a tribe of people ...</td>\n",
       "      <td>Florida, 1981 A little girl named Violet Hanse...</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>https://www.imdb.com/title/tt5606664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135003</th>\n",
       "      <td>135003</td>\n",
       "      <td>5213870</td>\n",
       "      <td>A young New York journalist returns to the idy...</td>\n",
       "      <td>young new york journalist return idyllic centr...</td>\n",
       "      <td>Pray for Rain</td>\n",
       "      <td>Pray for Rain</td>\n",
       "      <td>0.469513</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>['English']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When whip-smart New York City reporter Emma Ga...</td>\n",
       "      <td>A young New York journalist returns to the idy...</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>https://www.imdb.com/title/tt5213870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0       ID  \\\n",
       "134999      134999  1003009   \n",
       "135000      135000  1003009   \n",
       "135001      135001  1003009   \n",
       "135002      135002  5606664   \n",
       "135003      135003  5213870   \n",
       "\n",
       "                                                     text  \\\n",
       "134999  En su recorrido por el interior de la Casona E...   \n",
       "135000  Among these stories is \"The Legend of the Nahu...   \n",
       "135001  In his journey inside the bewitched house, Leo...   \n",
       "135002  She finds what looks like filing cabinets and ...   \n",
       "135003  A young New York journalist returns to the idy...   \n",
       "\n",
       "                                               text_clean  \\\n",
       "134999  en su recorrido por el interior de la casona e...   \n",
       "135000  among story legend nahuala accord old abandon ...   \n",
       "135001  journey inside bewitch house Leo face danger s...   \n",
       "135002  find look like filing cabinet try dig abra ant...   \n",
       "135003  young new york journalist return idyllic centr...   \n",
       "\n",
       "                                         Title            original_title  \\\n",
       "134999  Legend Quest: The Legend of La Nahuala  La leyenda de la Nahuala   \n",
       "135000  Legend Quest: The Legend of La Nahuala  La leyenda de la Nahuala   \n",
       "135001  Legend Quest: The Legend of La Nahuala  La leyenda de la Nahuala   \n",
       "135002                            Doctor Sleep              Doctor Sleep   \n",
       "135003                           Pray for Rain             Pray for Rain   \n",
       "\n",
       "        votes_score    year    languages overview  \\\n",
       "134999     0.419209  2007.0  ['Spanish']      NaN   \n",
       "135000     0.419209  2007.0  ['Spanish']      NaN   \n",
       "135001     0.419209  2007.0  ['Spanish']      NaN   \n",
       "135002     0.820093  2019.0  ['English']      NaN   \n",
       "135003     0.469513  2017.0  ['English']      NaN   \n",
       "\n",
       "                                             plot_outline  \\\n",
       "134999  The movie takes place in the year 1807 in the ...   \n",
       "135000  The movie takes place in the year 1807 in the ...   \n",
       "135001  The movie takes place in the year 1807 in the ...   \n",
       "135002  On highways across America, a tribe of people ...   \n",
       "135003  When whip-smart New York City reporter Emma Ga...   \n",
       "\n",
       "                                                 Synopsis  ID_Length zeros  \\\n",
       "134999  Sinópsis Corre el año de 1807 en la Ciudad de ...          7         \n",
       "135000  Sinópsis Corre el año de 1807 en la Ciudad de ...          7         \n",
       "135001  Sinópsis Corre el año de 1807 en la Ciudad de ...          7         \n",
       "135002  Florida, 1981 A little girl named Violet Hanse...          7         \n",
       "135003  A young New York journalist returns to the idy...          7         \n",
       "\n",
       "                                       Links  \n",
       "134999  https://www.imdb.com/title/tt1003009  \n",
       "135000  https://www.imdb.com/title/tt1003009  \n",
       "135001  https://www.imdb.com/title/tt1003009  \n",
       "135002  https://www.imdb.com/title/tt5606664  \n",
       "135003  https://www.imdb.com/title/tt5213870  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_movielens_final_new=pd.read_excel('C:/Users/cioffil/Desktop/DS/Github/Moviezam/Moviezam/data/movielens/data_movielens_final_new.xlsx')\n",
    "data_movielens_final_new['ID_Length']=data_movielens_final_new['ID'].astype(str).apply(len)\n",
    "data_movielens_final_new['zeros']=np.where(data_movielens_final_new['ID_Length']==7, '', np.where(data_movielens_final_new['ID_Length']==6,'0',np.where(data_movielens_final_new['ID_Length']==5,'00',np.where(data_movielens_final_new['ID_Length']==4,'000',np.where(data_movielens_final_new['ID_Length']==3,'0000',np.where(data_movielens_final_new['ID_Length']==2,'00000','000000'))))))\n",
    "data_movielens_final_new['Links'] = 'https://www.imdb.com/title/tt'+data_movielens_final_new['zeros']+data_movielens_final_new['ID'].astype(str)\n",
    "data_movielens_final_new.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "telegram_chatbots",
   "language": "python",
   "name": "telegram_chatbots"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
